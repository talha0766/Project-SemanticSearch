# -*- coding: utf-8 -*-
"""Semantic search

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ROTQruECqDFSZCbcW-Vy87YXG2SecL7I
"""

!gdown 1HNkPcPP3n8Im72SFNUuaHHUf2fxYmfeD

import pandas as pd
import math
import re
from collections import defaultdict

file_name = 'dictionary.csv'
df = pd.read_csv(file_name)
df.columns = ['letter', 'pos', 'gloss']
df.dropna(subset=['gloss'], inplace=True)
df.reset_index(drop=True, inplace=True)

if 'word' not in df.columns:
    df['word'] = [f"{row.letter}_{i}" for i, row in df.iterrows()]

def tokenize(text):
    return re.findall(r'\b[a-z]{2,}\b', text.lower())

token_counts_docs = []
doc_freq = defaultdict(int)
vocab = set()

for gloss in df['gloss']:
    tokens = tokenize(gloss)
    token_counts = defaultdict(int)
    for token in tokens:
        token_counts[token] += 1
    token_counts_docs.append(token_counts)
    for token in token_counts.keys():
        doc_freq[token] += 1
    vocab.update(token_counts.keys())

vocab = sorted(vocab)
vocab_index = {word: i for i, word in enumerate(vocab)}
N = len(token_counts_docs)

idf = {token: math.log(N / (1 + dfreq)) for token, dfreq in doc_freq.items()}

def compute_sparse_tfidf(token_counts_docs, vocab_index, idf):
    sparse_tfidf = []
    for token_counts in token_counts_docs:
        total_tokens = sum(token_counts.values())
        tfidf_vector = {}
        for token, count in token_counts.items():
            if token in vocab_index:
                tf = count / total_tokens
                tfidf_vector[vocab_index[token]] = tf * idf[token]
        sparse_tfidf.append(tfidf_vector)
    return sparse_tfidf

sparse_tfidf_matrix = compute_sparse_tfidf(token_counts_docs, vocab_index, idf)

def cosine_similarity_sparse(vec1, vec2):
    common_keys = vec1.keys() & vec2.keys()
    dot_product = sum(vec1[k] * vec2[k] for k in common_keys)
    norm1 = math.sqrt(sum(v ** 2 for v in vec1.values()))
    norm2 = math.sqrt(sum(v ** 2 for v in vec2.values()))
    if norm1 == 0 or norm2 == 0:
        return 0.0
    return dot_product / (norm1 * norm2)

def search_glosses(keyword, max_results=10):
    keyword_lower = keyword.lower()
    results = [(i, gloss) for i, gloss in enumerate(df['gloss']) if keyword_lower in gloss.lower()]
    for i, gloss in results[:max_results]:
        print(f"[{i}] {gloss}\n")

def find_most_similar(word, top_n=10):
    word_lower = word.lower()
    target_idx = None
    for idx, gloss in enumerate(df['gloss']):
        if re.search(rf'\b{re.escape(word_lower)}\b', gloss.lower()):
            target_idx = idx
            break

    if target_idx is None:
        print(f"Word '{word}' not found in any gloss.")
        return

    target_vec = sparse_tfidf_matrix[target_idx]
    print(f"\nMatched Gloss for '{word}':")
    print(f"→ Word: {df['word'][target_idx]}")
    print(f"→ Gloss: {df['gloss'][target_idx]}\n")

    similarities = [
        (i, cosine_similarity_sparse(target_vec, vec))
        for i, vec in enumerate(sparse_tfidf_matrix) if i != target_idx
    ]
    similarities.sort(key=lambda x: x[1], reverse=True)

    print(f"Top {top_n} Most Similar Glosses:\n")
    for rank, (i, score) in enumerate(similarities[:top_n], 1):
        print(f"→ Word: {df['word'][i].split('_')[0]}") #print(f"{rank}. Word: {df['word'][i]}")
        print(f"   Gloss: {df['gloss'][i]}")
        print(f"   Score: {score:.4f}\n")

def sentence_to_tfidf(sentence, vocab_index, idf):
    tokens = tokenize(sentence)
    token_counts = defaultdict(int)
    for token in tokens:
        token_counts[token] += 1
    total_tokens = len(tokens)
    tfidf_vector = {}
    for token, count in token_counts.items():
        if token in vocab_index:
            tf = count / total_tokens
            tfidf_vector[vocab_index[token]] = tf * idf[token]
    return tfidf_vector

def find_most_similar_sentence(sentence, top_n=10):
    sentence_vec = sentence_to_tfidf(sentence, vocab_index, idf)
    if not sentence_vec:
        print("None of the words in the sentence are in the dictionary vocabulary.")
        return

    similarities = [
        (i, cosine_similarity_sparse(sentence_vec, vec))
        for i, vec in enumerate(sparse_tfidf_matrix)
    ]
    similarities.sort(key=lambda x: x[1], reverse=True)

    print(f"Top {top_n} Most Similar Glosses for Sentence:\n→ '{sentence}'\n")
    for rank, (i, score) in enumerate(similarities[:top_n], 1):
        print(f"→ Word: {df['word'][i].split('_')[0]}") #print(f"{rank}. Word: {df['word'][i]}")
        print(f"   Gloss: {df['gloss'][i]}")
        print(f"   Score: {score:.4f}\n")

def main():
    while True:
        print("\nWhat would you like to do?")
        print("1. Search for a keyword in glosses")
        print("2. Find glosses similar to a word")
        print("3. Find glosses similar to a sentence")
        print("4. Exit")

        choice = input("Enter your choice (1-4): ").strip()

        if choice == '1':
            keyword = input("Enter keyword to search in glosses: ").strip()
            search_glosses(keyword)
        elif choice == '2':
            word = input("Enter a word to find similar glosses: ").strip()
            find_most_similar(word)
        elif choice == '3':
            sentence = input("Enter a sentence to find similar glosses: ").strip()
            find_most_similar_sentence(sentence)
        elif choice == '4':
            print("Goodbye!")
            break
        else:
            print("Invalid choice. Please enter a number between 1 and 4.")

main()
